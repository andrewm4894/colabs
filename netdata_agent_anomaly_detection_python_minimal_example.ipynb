{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "netdata_agent_anomaly_detection_python_minimal_example.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOFmJjVpzxyS6c4B5cb/YzF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewm4894/colabs/blob/master/netdata_agent_anomaly_detection_python_minimal_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYUM6Qi2XwP1"
      },
      "source": [
        "# install dlib\r\n",
        "#!pip install dlib"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW8Sq6tYUDQl"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDqFxENLRG8P"
      },
      "source": [
        "## IMPORTS ##\r\n",
        "\r\n",
        "import pprint as pp\r\n",
        "import numpy as np\r\n",
        "import requests\r\n",
        "import time\r\n",
        "#import dlib\r\n",
        "from sklearn.cluster import KMeans, Birch\r\n",
        "from scipy.spatial.distance import cdist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5NFt_LEUFo2"
      },
      "source": [
        "## Inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kANixVF5RQ3L"
      },
      "source": [
        "## INPUTS ##\r\n",
        "\r\n",
        "# how many steps to run\r\n",
        "n_steps = 100\r\n",
        "\r\n",
        "# host to use data from\r\n",
        "host = 'london.my-netdata.io'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl-ojGolUH-n"
      },
      "source": [
        "## Model Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LACTF8_VRQwV",
        "outputId": "37e09864-dc0a-4b49-ad84-e05a5e0295c8"
      },
      "source": [
        "## MODEL CONFIG ##\r\n",
        "\r\n",
        "# define the config for each model we want a score for\r\n",
        "config = {\r\n",
        "    # a nice name for the model\r\n",
        "    \"just_cpu_user_and_system\": {\r\n",
        "        # define what metrics we want\r\n",
        "        \"metrics\": {\r\n",
        "            # chart: ['dims']\r\n",
        "            \"system.cpu\": [\"user\", \"system\"]\r\n",
        "            },\r\n",
        "        # params specific to the model\r\n",
        "        \"params\": {\r\n",
        "            \"diffs\": True, \"n_smoothing\": 3, \"train_data_size\": 25, \r\n",
        "            \"train_every_n\": 50, \"n_lags\": 3, \"n_clusters\": 2, \"anomaly_score_cap\": 5\r\n",
        "            }\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "pp.pprint(config)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'just_cpu_user_and_system': {'metrics': {'system.cpu': ['user', 'system']},\n",
            "                              'params': {'anomaly_score_cap': 5,\n",
            "                                         'diffs': True,\n",
            "                                         'n_clusters': 2,\n",
            "                                         'n_lags': 3,\n",
            "                                         'n_smoothing': 3,\n",
            "                                         'train_data_size': 25,\n",
            "                                         'train_every_n': 50}}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WoDQ_8vUMFd"
      },
      "source": [
        "## Some Set Up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ogguerw4RzNY",
        "outputId": "8c4371cb-2a08-4e56-87f1-31dd4b512709"
      },
      "source": [
        "# define a mapping from models to data keys used later to combine preprocessed data into model data for one or more metrics\r\n",
        "model_data_key_map = {}\r\n",
        "for model in config:\r\n",
        "    for chart in config[model]['metrics']:\r\n",
        "        for dim in config[model]['metrics'][chart]:\r\n",
        "            data_key = f'{chart}|{dim}'\r\n",
        "            if model not in model_data_key_map:\r\n",
        "                model_data_key_map[model] = [data_key]\r\n",
        "            else:\r\n",
        "                model_data_key_map[model].append(data_key)\r\n",
        "\r\n",
        "pp.pprint(model_data_key_map)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'just_cpu_user_and_system': ['system.cpu|user', 'system.cpu|system']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzjL3s98SGmN"
      },
      "source": [
        "# hold onto some data for training when needed\r\n",
        "data_history_raw = {}\r\n",
        "data_history_processed = {}\r\n",
        "\r\n",
        "# initialize some model objects\r\n",
        "models = {model: None for model in config}\r\n",
        "model_train_data = {model: [] for model in config}\r\n",
        "model_predict_data = {model: [] for model in config}\r\n",
        "models_meta = {model: {} for model in config}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqAc0kSwUOze"
      },
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lXHu1D0Rhhx"
      },
      "source": [
        "## HELPER FUNCTIONS ##\r\n",
        "\r\n",
        "\r\n",
        "def preprocess_data(x, n_smoothing, n_lags, diffs, print_steps=False):\r\n",
        "    \"\"\"Function to preprocess a vector of data. \r\n",
        "    1. do smoothing by averaging over rolling window of n_smoothing.\r\n",
        "    2. take differences if specified.\r\n",
        "    3. add lagged values to the vector and trim it accordingly.\r\n",
        "    \"\"\"\r\n",
        "    \r\n",
        "    if print_steps:\r\n",
        "        print(f'n_smoothing={n_smoothing}, diffs={diffs}, n_lags={n_lags}')\r\n",
        "        print('x:           ', x)\r\n",
        "    \r\n",
        "    # smoothing\r\n",
        "    i = 0\r\n",
        "    x_processed = []\r\n",
        "    while i < len(x) - n_smoothing + 1:\r\n",
        "        x_window = x[i : i + n_smoothing]\r\n",
        "        window_average = sum(x_window) / n_smoothing\r\n",
        "        x_processed.append(round(window_average,2))\r\n",
        "        i += 1    \r\n",
        "    \r\n",
        "    if print_steps:\r\n",
        "        print('x smoothed:  ', x_processed)\r\n",
        "\r\n",
        "    # differences\r\n",
        "    if diffs:\r\n",
        "        x_processed = [round(j-i,2) for i, j in zip(x_processed[:-1], x_processed[1:])]\r\n",
        "        \r\n",
        "        if print_steps:\r\n",
        "            print('x diff:      ', x_processed)\r\n",
        "\r\n",
        "    # add lagged values\r\n",
        "    x_processed = x_processed[-(n_lags+1):]\r\n",
        "    \r\n",
        "    if print_steps:\r\n",
        "        print('x lagged:    ', x_processed)\r\n",
        "    \r\n",
        "    if print_steps:\r\n",
        "        print('x processed: ', x_processed)    \r\n",
        "\r\n",
        "    return x_processed\r\n",
        "\r\n",
        "\r\n",
        "def get_params_from_config(config, model):\r\n",
        "    \r\n",
        "    diffs = config[model]['params']['diffs']\r\n",
        "    n_smoothing = config[model]['params']['n_smoothing']\r\n",
        "    train_data_size = config[model]['params']['train_data_size']\r\n",
        "    train_every_n = config[model]['params']['train_every_n']\r\n",
        "    n_lags = config[model]['params']['n_lags']\r\n",
        "    n_clusters = config[model]['params']['n_clusters']\r\n",
        "    anomaly_score_cap = config[model]['params']['anomaly_score_cap']\r\n",
        "\r\n",
        "    return diffs, n_smoothing, train_data_size, train_every_n, n_lags, n_clusters, anomaly_score_cap\r\n",
        "\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDcSHJOtUSCu"
      },
      "source": [
        "## Generate Anomaly Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xyNsYjkRhfQ",
        "outputId": "2ec40ff7-7cf2-4851-b3a2-2a5aee09a54e"
      },
      "source": [
        "## ALGO ##\r\n",
        "\r\n",
        "# run each step\r\n",
        "for n in range(n_steps):\r\n",
        "\r\n",
        "    # for each model defined in config\r\n",
        "    for model in config:\r\n",
        "\r\n",
        "        # get params for the model\r\n",
        "        diffs, n_smoothing, train_data_size, train_every_n, n_lags, n_clusters, anomaly_score_cap = get_params_from_config(config, model)\r\n",
        "\r\n",
        "        # get latest data from /allmetrics \r\n",
        "        r = requests.get(f'https://{host}/api/v1/allmetrics?format=json')\r\n",
        "        data_now_raw = r.json()\r\n",
        "\r\n",
        "        # for each chart from the host that we are using in the model\r\n",
        "        for chart in config[model]['metrics']:\r\n",
        "\r\n",
        "            # for each dim we want from that chart\r\n",
        "            for dim in config[model]['metrics'][chart]:\r\n",
        "\r\n",
        "                # create a key value for current data we want to use\r\n",
        "                data_key = f'{chart}|{dim}'\r\n",
        "                data_value = data_now_raw[chart]['dimensions'][dim]['value']\r\n",
        "                    \r\n",
        "                # append data to relevant part of raw history data map\r\n",
        "                if data_key not in data_history_raw:\r\n",
        "                    data_history_raw[data_key] = [data_value]\r\n",
        "                else:\r\n",
        "                    data_history_raw[data_key].append(data_value)\r\n",
        "\r\n",
        "                # limit raw history to recent data needed for preprocessing\r\n",
        "                data_history_raw[data_key] = data_history_raw[data_key][-(n_smoothing + n_lags + 3):]\r\n",
        "\r\n",
        "                # process current data and store it for use by training and prediction\r\n",
        "                data_now_processed = preprocess_data(data_history_raw[data_key], n_smoothing, n_lags, diffs)\r\n",
        "                if data_key not in data_history_processed:\r\n",
        "                    data_history_processed[data_key] = [data_now_processed]\r\n",
        "                else:\r\n",
        "                    data_history_processed[data_key].append(data_now_processed)\r\n",
        "\r\n",
        "                # print example of processing for last observation\r\n",
        "                if n == (n_steps-1):\r\n",
        "                    print(f'\\nprinting example preprocess steps for {data_key} at step {n}\\n')\r\n",
        "                    _ = preprocess_data(data_history_raw[data_key], n_smoothing, n_lags, diffs, print_steps=True)\r\n",
        "\r\n",
        "        # train model if needed\r\n",
        "        if n >= train_data_size and n % train_every_n == 0:\r\n",
        "\r\n",
        "            # gather together preprocessed data for each dim from each model            \r\n",
        "            train_data_offset = len(data_history_processed[model_data_key_map[model][0]]) - train_data_size\r\n",
        "\r\n",
        "            # loop over each training observation we expect to have\r\n",
        "            for i in range(train_data_size):\r\n",
        "\r\n",
        "                x = []\r\n",
        "                # get the metrics for each training observation for each metric used by the model\r\n",
        "                \r\n",
        "                for dim in model_data_key_map[model]:\r\n",
        "\r\n",
        "                    # extend the feature vector for the model to add the dim features\r\n",
        "                    x.extend(data_history_processed[dim][(train_data_offset+i)])\r\n",
        "                \r\n",
        "                # append the training observation to the model data\r\n",
        "                model_train_data[model].append(x)\r\n",
        "\r\n",
        "            # just keep most recent train_data_size values\r\n",
        "            model_train_data[model] = model_train_data[model][-train_data_size:]\r\n",
        "\r\n",
        "            # make sure we only use training data with the expected shape\r\n",
        "            model_n_dims = len(model_data_key_map[model])\r\n",
        "            model_feature_vector_len = model_n_dims * (n_lags + 1)            \r\n",
        "            train_data = [x for x in model_train_data[model] if len(x) == model_feature_vector_len]\r\n",
        "\r\n",
        "            print(f'...training model {model} at step {n} on {len(train_data)} processed observations each a list of {len(train_data[-1])} numbers')\r\n",
        "\r\n",
        "            # fit a kmeans with n_clusters\r\n",
        "            models[model] = KMeans(n_clusters=n_clusters)\r\n",
        "            models[model].fit(train_data)\r\n",
        "\r\n",
        "            # get min and max distances observed in the train data (used to scale predictions later to be 0,1 range)\r\n",
        "            train_dists = cdist(train_data, models[model].cluster_centers_)\r\n",
        "\r\n",
        "            # store model meta data used for scaling at prediction time\r\n",
        "            models_meta[model]['max_dist'] = np.max(np.mean(train_dists, axis=1))\r\n",
        "            models_meta[model]['min_dist'] = np.min(np.mean(train_dists, axis=1))\r\n",
        "\r\n",
        "        # gather recent data for model prediction once model has been trained\r\n",
        "        if models[model]:\r\n",
        "            x = []\r\n",
        "            for dim in model_data_key_map[model]:\r\n",
        "                x.extend(data_history_processed[dim][-1])\r\n",
        "\r\n",
        "            pred_data = [x]\r\n",
        "\r\n",
        "            # get anomaly score for latest processed data\r\n",
        "            anomaly_score = round(np.mean(cdist(pred_data, models[model].cluster_centers_)), 2)\r\n",
        "\r\n",
        "            # min/max normalize based on training data\r\n",
        "            anomaly_score_scaled = (anomaly_score - models_meta[model]['min_dist']) / (models_meta[model]['max_dist'] - models_meta[model]['min_dist'])\r\n",
        "            \r\n",
        "            # cap anomaly score\r\n",
        "            anomaly_score_scaled = min(anomaly_score_scaled, anomaly_score_cap)\r\n",
        "\r\n",
        "            print(f'...anomaly score at step {n} for model {model} = {anomaly_score_scaled}')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "...training model just_cpu_user_and_system at step 50 on 25 processed observations each a list of 8 numbers\n",
            "...anomaly score at step 50 for model just_cpu_user_and_system = 0.1647794787210567\n",
            "...anomaly score at step 51 for model just_cpu_user_and_system = 0.312464692001299\n",
            "...anomaly score at step 52 for model just_cpu_user_and_system = 0.4232286019614808\n",
            "...anomaly score at step 53 for model just_cpu_user_and_system = 0.4232286019614808\n",
            "...anomaly score at step 54 for model just_cpu_user_and_system = 0.5155318602616321\n",
            "...anomaly score at step 55 for model just_cpu_user_and_system = 0.5155318602616321\n",
            "...anomaly score at step 56 for model just_cpu_user_and_system = 0.5155318602616321\n",
            "...anomaly score at step 57 for model just_cpu_user_and_system = 0.5155318602616321\n",
            "...anomaly score at step 58 for model just_cpu_user_and_system = 0.4047679503014505\n",
            "...anomaly score at step 59 for model just_cpu_user_and_system = 0.47861055694157156\n",
            "...anomaly score at step 60 for model just_cpu_user_and_system = 0.49707120860160187\n",
            "...anomaly score at step 61 for model just_cpu_user_and_system = 0.6816777252019047\n",
            "...anomaly score at step 62 for model just_cpu_user_and_system = 0.6816777252019047\n",
            "...anomaly score at step 63 for model just_cpu_user_and_system = 0.49707120860160187\n",
            "...anomaly score at step 64 for model just_cpu_user_and_system = 0.3309253436613293\n",
            "...anomaly score at step 65 for model just_cpu_user_and_system = 0.10939752374096588\n",
            "...anomaly score at step 66 for model just_cpu_user_and_system = 0.05401556876087497\n",
            "...anomaly score at step 67 for model just_cpu_user_and_system = 0.05401556876087497\n",
            "...anomaly score at step 68 for model just_cpu_user_and_system = 0.3678466469813899\n",
            "...anomaly score at step 69 for model just_cpu_user_and_system = 0.5893744669017533\n",
            "...anomaly score at step 70 for model just_cpu_user_and_system = 0.7555203318420259\n",
            "...anomaly score at step 71 for model just_cpu_user_and_system = 0.7555203318420259\n",
            "...anomaly score at step 72 for model just_cpu_user_and_system = 0.570913815241723\n",
            "...anomaly score at step 73 for model just_cpu_user_and_system = 0.3678466469813899\n",
            "...anomaly score at step 74 for model just_cpu_user_and_system = 0.12785817540099617\n",
            "...anomaly score at step 75 for model just_cpu_user_and_system = 0.183240130381087\n",
            "...anomaly score at step 76 for model just_cpu_user_and_system = 0.183240130381087\n",
            "...anomaly score at step 77 for model just_cpu_user_and_system = 0.12785817540099617\n",
            "...anomaly score at step 78 for model just_cpu_user_and_system = 0.183240130381087\n",
            "...anomaly score at step 79 for model just_cpu_user_and_system = 0.2386220853611779\n",
            "...anomaly score at step 80 for model just_cpu_user_and_system = 0.312464692001299\n",
            "...anomaly score at step 81 for model just_cpu_user_and_system = 0.312464692001299\n",
            "...anomaly score at step 82 for model just_cpu_user_and_system = 0.2386220853611779\n",
            "...anomaly score at step 83 for model just_cpu_user_and_system = 0.12785817540099617\n",
            "...anomaly score at step 84 for model just_cpu_user_and_system = 0.01709426544081446\n",
            "...anomaly score at step 85 for model just_cpu_user_and_system = 0.05401556876087497\n",
            "...anomaly score at step 86 for model just_cpu_user_and_system = 0.10939752374096588\n",
            "...anomaly score at step 87 for model just_cpu_user_and_system = 0.1463188270610264\n",
            "...anomaly score at step 88 for model just_cpu_user_and_system = 0.10939752374096588\n",
            "...anomaly score at step 89 for model just_cpu_user_and_system = 0.3309253436613293\n",
            "...anomaly score at step 90 for model just_cpu_user_and_system = 0.3863072986414202\n",
            "...anomaly score at step 91 for model just_cpu_user_and_system = 0.3863072986414202\n",
            "...anomaly score at step 92 for model just_cpu_user_and_system = 0.3863072986414202\n",
            "...anomaly score at step 93 for model just_cpu_user_and_system = 0.5339925119216624\n",
            "...anomaly score at step 94 for model just_cpu_user_and_system = 0.6262957702218139\n",
            "...anomaly score at step 95 for model just_cpu_user_and_system = 0.6632170735418744\n",
            "...anomaly score at step 96 for model just_cpu_user_and_system = 0.6632170735418744\n",
            "...anomaly score at step 97 for model just_cpu_user_and_system = 0.47861055694157156\n",
            "...anomaly score at step 98 for model just_cpu_user_and_system = 0.3309253436613293\n",
            "\n",
            "printing example preprocess steps for system.cpu|user at step 99\n",
            "\n",
            "n_smoothing=3, diffs=True, n_lags=3\n",
            "x:            [1.2531328, 1.2531328, 1.9950125, 1.9950125, 1.9950125, 1.9950125, 1.9950125, 2.0, 2.0]\n",
            "x smoothed:   [1.5, 1.75, 2.0, 2.0, 2.0, 2.0, 2.0]\n",
            "x diff:       [0.25, 0.25, 0.0, 0.0, 0.0, 0.0]\n",
            "x lagged:     [0.0, 0.0, 0.0, 0.0]\n",
            "x processed:  [0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "printing example preprocess steps for system.cpu|system at step 99\n",
            "\n",
            "n_smoothing=3, diffs=True, n_lags=3\n",
            "x:            [1.0025063, 1.0025063, 0.7481297, 0.7481297, 0.7481297, 0.7481297, 0.7481297, 1.25, 1.25]\n",
            "x smoothed:   [0.92, 0.83, 0.75, 0.75, 0.75, 0.92, 1.08]\n",
            "x diff:       [-0.09, -0.08, 0.0, 0.0, 0.17, 0.16]\n",
            "x lagged:     [0.0, 0.0, 0.17, 0.16]\n",
            "x processed:  [0.0, 0.0, 0.17, 0.16]\n",
            "...anomaly score at step 99 for model just_cpu_user_and_system = 0.1647794787210567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_wlkBYaxGoS"
      },
      "source": [
        "## Look at some objects we have used"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCPJsWYNRQon",
        "outputId": "61a23153-78f6-4265-dff3-02b4616cf2ff"
      },
      "source": [
        "# used to stored some recent raw data we need to process recent data\r\n",
        "print(model)\r\n",
        "data_history_raw"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "just_cpu_user_and_system\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'system.cpu|system': [1.0025063,\n",
              "  1.0025063,\n",
              "  0.7481297,\n",
              "  0.7481297,\n",
              "  0.7481297,\n",
              "  0.7481297,\n",
              "  0.7481297,\n",
              "  1.25,\n",
              "  1.25],\n",
              " 'system.cpu|user': [1.2531328,\n",
              "  1.2531328,\n",
              "  1.9950125,\n",
              "  1.9950125,\n",
              "  1.9950125,\n",
              "  1.9950125,\n",
              "  1.9950125,\n",
              "  2.0,\n",
              "  2.0]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wzt5fe-5rv0X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0eea6262-ba8f-4384-e613-3a24939a3573"
      },
      "source": [
        "# a history or processed observations we use when training \r\n",
        "# and to use most recent one when getting anomaly score\r\n",
        "print(model)\r\n",
        "data_history_processed"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "just_cpu_user_and_system\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'system.cpu|system': [[],\n",
              "  [],\n",
              "  [],\n",
              "  [0.17],\n",
              "  [0.17, 0.16],\n",
              "  [0.17, 0.16, 0.17],\n",
              "  [0.17, 0.16, 0.17, 0.0],\n",
              "  [0.16, 0.17, 0.0, 0.0],\n",
              "  [0.17, 0.0, 0.0, -0.08],\n",
              "  [0.0, 0.0, -0.08, -0.09],\n",
              "  [0.0, -0.08, -0.09, -0.08],\n",
              "  [-0.08, -0.09, -0.08, 0.0],\n",
              "  [-0.09, -0.08, 0.0, 0.33],\n",
              "  [-0.08, 0.0, 0.33, 0.33],\n",
              "  [0.0, 0.33, 0.33, 0.34],\n",
              "  [0.33, 0.33, 0.34, 0.0],\n",
              "  [0.33, 0.34, 0.0, 0.0],\n",
              "  [0.34, 0.0, 0.0, -0.33],\n",
              "  [0.0, 0.0, -0.33, -0.33],\n",
              "  [0.0, -0.33, -0.33, -0.33],\n",
              "  [-0.33, -0.33, -0.33, 0.0],\n",
              "  [-0.33, -0.33, 0.0, -0.01],\n",
              "  [-0.33, 0.0, -0.01, 0.0],\n",
              "  [0.0, -0.01, 0.0, 0.0],\n",
              "  [-0.01, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.17],\n",
              "  [0.0, 0.0, 0.17, 0.17],\n",
              "  [0.0, 0.17, 0.17, 0.17],\n",
              "  [0.17, 0.17, 0.17, 0.0],\n",
              "  [0.17, 0.17, 0.0, -0.17],\n",
              "  [0.17, 0.0, -0.17, -0.17],\n",
              "  [0.0, -0.17, -0.17, -0.16],\n",
              "  [-0.17, -0.17, -0.16, 0.0],\n",
              "  [-0.17, -0.16, 0.0, -0.17],\n",
              "  [-0.16, 0.0, -0.17, -0.17],\n",
              "  [0.0, -0.17, -0.17, -0.17],\n",
              "  [-0.17, -0.17, -0.17, 0.0],\n",
              "  [-0.17, -0.17, 0.0, 0.0],\n",
              "  [-0.17, 0.0, 0.0, 0.17],\n",
              "  [0.0, 0.0, 0.17, 0.17],\n",
              "  [0.0, 0.17, 0.17, 0.16],\n",
              "  [0.17, 0.17, 0.16, 0.0],\n",
              "  [0.17, 0.16, 0.0, 0.0],\n",
              "  [0.16, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.01],\n",
              "  [0.0, 0.0, 0.01, 0.0],\n",
              "  [0.0, 0.01, 0.0, 0.0],\n",
              "  [0.01, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, -0.09],\n",
              "  [0.0, 0.0, -0.09, -0.08],\n",
              "  [0.0, -0.09, -0.08, -0.09],\n",
              "  [-0.09, -0.08, -0.09, 0.0],\n",
              "  [-0.08, -0.09, 0.0, 0.34],\n",
              "  [-0.09, 0.0, 0.34, 0.33],\n",
              "  [0.0, 0.34, 0.33, 0.33],\n",
              "  [0.34, 0.33, 0.33, 0.0],\n",
              "  [0.33, 0.33, 0.0, 0.0],\n",
              "  [0.33, 0.0, 0.0, -0.08],\n",
              "  [0.0, 0.0, -0.08, -0.08],\n",
              "  [0.0, -0.08, -0.08, -0.07],\n",
              "  [-0.08, -0.08, -0.07, 0.0],\n",
              "  [-0.08, -0.07, 0.0, 0.0],\n",
              "  [-0.07, 0.0, 0.0, 0.07],\n",
              "  [0.0, 0.0, 0.07, 0.08],\n",
              "  [0.0, 0.07, 0.08, 0.08],\n",
              "  [0.07, 0.08, 0.08, 0.0],\n",
              "  [0.08, 0.08, 0.0, -0.33],\n",
              "  [0.08, 0.0, -0.33, -0.34],\n",
              "  [0.0, -0.33, -0.34, -0.33],\n",
              "  [-0.33, -0.34, -0.33, 0.0],\n",
              "  [-0.34, -0.33, 0.0, 0.0],\n",
              "  [-0.33, 0.0, 0.0, 0.09],\n",
              "  [0.0, 0.0, 0.09, 0.08],\n",
              "  [0.0, 0.09, 0.08, 0.08],\n",
              "  [0.09, 0.08, 0.08, 0.0],\n",
              "  [0.08, 0.08, 0.0, 0.0],\n",
              "  [0.08, 0.0, 0.0, 0.16],\n",
              "  [0.0, 0.0, 0.16, 0.17],\n",
              "  [0.0, 0.16, 0.17, 0.16],\n",
              "  [0.16, 0.17, 0.16, 0.0],\n",
              "  [0.17, 0.16, 0.0, 0.0],\n",
              "  [0.16, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.01],\n",
              "  [0.0, 0.0, 0.01, 0.0],\n",
              "  [0.0, 0.01, 0.0, -0.08],\n",
              "  [0.01, 0.0, -0.08, -0.09],\n",
              "  [0.0, -0.08, -0.09, -0.08],\n",
              "  [-0.08, -0.09, -0.08, 0.0],\n",
              "  [-0.09, -0.08, 0.0, -0.08],\n",
              "  [-0.08, 0.0, -0.08, -0.09],\n",
              "  [0.0, -0.08, -0.09, -0.08],\n",
              "  [-0.08, -0.09, -0.08, 0.0],\n",
              "  [-0.09, -0.08, 0.0, 0.0],\n",
              "  [-0.08, 0.0, 0.0, 0.17],\n",
              "  [0.0, 0.0, 0.17, 0.16]],\n",
              " 'system.cpu|user': [[],\n",
              "  [],\n",
              "  [],\n",
              "  [0.16],\n",
              "  [0.16, 0.17],\n",
              "  [0.16, 0.17, 0.16],\n",
              "  [0.16, 0.17, 0.16, 0.0],\n",
              "  [0.17, 0.16, 0.0, 0.0],\n",
              "  [0.16, 0.0, 0.0, 0.08],\n",
              "  [0.0, 0.0, 0.08, 0.09],\n",
              "  [0.0, 0.08, 0.09, 0.08],\n",
              "  [0.08, 0.09, 0.08, 0.0],\n",
              "  [0.09, 0.08, 0.0, 0.17],\n",
              "  [0.08, 0.0, 0.17, 0.16],\n",
              "  [0.0, 0.17, 0.16, 0.16],\n",
              "  [0.17, 0.16, 0.16, 0.0],\n",
              "  [0.16, 0.16, 0.0, 0.0],\n",
              "  [0.16, 0.0, 0.0, -0.32],\n",
              "  [0.0, 0.0, -0.32, -0.33],\n",
              "  [0.0, -0.32, -0.33, -0.33],\n",
              "  [-0.32, -0.33, -0.33, 0.0],\n",
              "  [-0.33, -0.33, 0.0, 0.08],\n",
              "  [-0.33, 0.0, 0.08, 0.08],\n",
              "  [0.0, 0.08, 0.08, 0.08],\n",
              "  [0.08, 0.08, 0.08, 0.0],\n",
              "  [0.08, 0.08, 0.0, 0.0],\n",
              "  [0.08, 0.0, 0.0, 0.01],\n",
              "  [0.0, 0.0, 0.01, 0.0],\n",
              "  [0.0, 0.01, 0.0, 0.01],\n",
              "  [0.01, 0.0, 0.01, 0.0],\n",
              "  [0.0, 0.01, 0.0, -0.01],\n",
              "  [0.01, 0.0, -0.01, 0.0],\n",
              "  [0.0, -0.01, 0.0, 0.0],\n",
              "  [-0.01, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.33],\n",
              "  [0.0, 0.0, 0.33, 0.33],\n",
              "  [0.0, 0.33, 0.33, 0.33],\n",
              "  [0.33, 0.33, 0.33, 0.0],\n",
              "  [0.33, 0.33, 0.0, 0.0],\n",
              "  [0.33, 0.0, 0.0, -0.41],\n",
              "  [0.0, 0.0, -0.41, -0.42],\n",
              "  [0.0, -0.41, -0.42, -0.41],\n",
              "  [-0.41, -0.42, -0.41, 0.0],\n",
              "  [-0.42, -0.41, 0.0, 0.0],\n",
              "  [-0.41, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.17],\n",
              "  [0.0, 0.0, 0.17, 0.17],\n",
              "  [0.0, 0.17, 0.17, 0.16],\n",
              "  [0.17, 0.17, 0.16, 0.0],\n",
              "  [0.17, 0.16, 0.0, -0.08],\n",
              "  [0.16, 0.0, -0.08, -0.09],\n",
              "  [0.0, -0.08, -0.09, -0.09],\n",
              "  [-0.08, -0.09, -0.09, 0.0],\n",
              "  [-0.09, -0.09, 0.0, 0.0],\n",
              "  [-0.09, 0.0, 0.0, 0.26],\n",
              "  [0.0, 0.0, 0.26, 0.26],\n",
              "  [0.0, 0.26, 0.26, 0.26],\n",
              "  [0.26, 0.26, 0.26, 0.0],\n",
              "  [0.26, 0.26, 0.0, 0.0],\n",
              "  [0.26, 0.0, 0.0, -0.18],\n",
              "  [0.0, 0.0, -0.18, -0.18],\n",
              "  [0.0, -0.18, -0.18, -0.17],\n",
              "  [-0.18, -0.18, -0.17, 0.0],\n",
              "  [-0.18, -0.17, 0.0, 0.0],\n",
              "  [-0.17, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.01],\n",
              "  [0.0, 0.0, 0.01, 0.0],\n",
              "  [0.0, 0.01, 0.0, 0.0],\n",
              "  [0.01, 0.0, 0.0, 0.08],\n",
              "  [0.0, 0.0, 0.08, 0.08],\n",
              "  [0.0, 0.08, 0.08, 0.08],\n",
              "  [0.08, 0.08, 0.08, 0.0],\n",
              "  [0.08, 0.08, 0.0, 0.0],\n",
              "  [0.08, 0.0, 0.0, 0.08],\n",
              "  [0.0, 0.0, 0.08, 0.08],\n",
              "  [0.0, 0.08, 0.08, 0.08],\n",
              "  [0.08, 0.08, 0.08, 0.0],\n",
              "  [0.08, 0.08, 0.0, -0.09],\n",
              "  [0.08, 0.0, -0.09, -0.08],\n",
              "  [0.0, -0.09, -0.08, -0.08],\n",
              "  [-0.09, -0.08, -0.08, 0.08],\n",
              "  [-0.08, -0.08, 0.08, 0.09],\n",
              "  [-0.08, 0.08, 0.09, 0.08],\n",
              "  [0.08, 0.09, 0.08, 0.0],\n",
              "  [0.09, 0.08, 0.0, -0.33],\n",
              "  [0.08, 0.0, -0.33, -0.33],\n",
              "  [0.0, -0.33, -0.33, -0.33],\n",
              "  [-0.33, -0.33, -0.33, 0.0],\n",
              "  [-0.33, -0.33, 0.0, 0.25],\n",
              "  [-0.33, 0.0, 0.25, 0.25],\n",
              "  [0.0, 0.25, 0.25, 0.25],\n",
              "  [0.25, 0.25, 0.25, 0.0],\n",
              "  [0.25, 0.25, 0.0, 0.0],\n",
              "  [0.25, 0.0, 0.0, 0.0],\n",
              "  [0.0, 0.0, 0.0, 0.0]]}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlfoR1srrvoB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44d8ef1a-aa29-4101-dc47-4f6bd9142695"
      },
      "source": [
        "# the actual data the model is trained on\r\n",
        "# a concatenated list of each processed vector for each metric used in the model\r\n",
        "print(model)\r\n",
        "train_data"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "just_cpu_user_and_system\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.08, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.17],\n",
              " [0.0, 0.0, 0.01, 0.0, 0.0, 0.0, 0.17, 0.17],\n",
              " [0.0, 0.01, 0.0, 0.01, 0.0, 0.17, 0.17, 0.17],\n",
              " [0.01, 0.0, 0.01, 0.0, 0.17, 0.17, 0.17, 0.0],\n",
              " [0.0, 0.01, 0.0, -0.01, 0.17, 0.17, 0.0, -0.17],\n",
              " [0.01, 0.0, -0.01, 0.0, 0.17, 0.0, -0.17, -0.17],\n",
              " [0.0, -0.01, 0.0, 0.0, 0.0, -0.17, -0.17, -0.16],\n",
              " [-0.01, 0.0, 0.0, 0.0, -0.17, -0.17, -0.16, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.33, -0.17, -0.16, 0.0, -0.17],\n",
              " [0.0, 0.0, 0.33, 0.33, -0.16, 0.0, -0.17, -0.17],\n",
              " [0.0, 0.33, 0.33, 0.33, 0.0, -0.17, -0.17, -0.17],\n",
              " [0.33, 0.33, 0.33, 0.0, -0.17, -0.17, -0.17, 0.0],\n",
              " [0.33, 0.33, 0.0, 0.0, -0.17, -0.17, 0.0, 0.0],\n",
              " [0.33, 0.0, 0.0, -0.41, -0.17, 0.0, 0.0, 0.17],\n",
              " [0.0, 0.0, -0.41, -0.42, 0.0, 0.0, 0.17, 0.17],\n",
              " [0.0, -0.41, -0.42, -0.41, 0.0, 0.17, 0.17, 0.16],\n",
              " [-0.41, -0.42, -0.41, 0.0, 0.17, 0.17, 0.16, 0.0],\n",
              " [-0.42, -0.41, 0.0, 0.0, 0.17, 0.16, 0.0, 0.0],\n",
              " [-0.41, 0.0, 0.0, 0.0, 0.16, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.01, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [0.0, 0.0, 0.0, 0.17, 0.0, 0.0, 0.0, -0.09]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7VPd9_hg--T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ed680b-e14e-4bad-95a4-511dbbddc91b"
      },
      "source": [
        "# the feature vector used for the most recent anomaly score\r\n",
        "print(model)\r\n",
        "pred_data"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "just_cpu_user_and_system\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.17, 0.16]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC23wbGWNtDD"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWwHOVYHhvy_"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    }
  ]
}