{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_1528\\2996952205.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mio\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwandb\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import pandas as pd\n",
    "from keras.models import Model\n",
    "import wandb\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "import re\n",
    "import tempfile\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def model_summary_to_df(model) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a Keras model summary to a pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        model: The Keras model to convert the summary of.\n",
    "\n",
    "    Returns:\n",
    "        A pandas DataFrame containing the model summary information.\n",
    "\n",
    "    \"\"\"\n",
    "    # Capture the model summary\n",
    "    stream = io.StringIO()\n",
    "    model.summary(print_fn=lambda x: stream.write(x + \"\\n\"))\n",
    "    summary_string = stream.getvalue()\n",
    "    stream.close()\n",
    "\n",
    "    # Split summary into lines\n",
    "    lines = summary_string.split(\"\\n\")\n",
    "\n",
    "    # Dynamically find the header line\n",
    "    header_line_index = 0\n",
    "    for i, line in enumerate(lines[:4]):  # Header should be within the first few lines\n",
    "        if \"Output Shape\" in line and \"Param #\" in line:\n",
    "            header_line_index = i\n",
    "            break\n",
    "\n",
    "    # Use the found header line to determine column start positions\n",
    "    header_line = lines[header_line_index]\n",
    "    col_names = [\"Layer\", \"Output Shape\", \"Param #\"]\n",
    "    col_starts = [header_line.index(col_name) for col_name in col_names]\n",
    "\n",
    "    # Parse the model summary string\n",
    "    parsed_lines = lines[header_line_index + 2 : -5]  # Adjusted to skip the header\n",
    "    summary_info = lines[-5:]  # Final summary rows\n",
    "\n",
    "    data = []\n",
    "    # Parse layer information using column start positions\n",
    "    for line in parsed_lines:\n",
    "        if line and len(line.strip(\" \")) > 0:  # Non-empty line\n",
    "            layer = line[: col_starts[1]].strip()\n",
    "            output_shape = line[col_starts[1] : col_starts[2]].strip()\n",
    "            params = line[col_starts[2] :].strip()\n",
    "            data.append([layer, output_shape, params])\n",
    "\n",
    "    # Parse and add summary info\n",
    "    for info in summary_info:\n",
    "        if info:  # Check if the line is not empty\n",
    "            parts = info.split(\":\")\n",
    "            if len(parts) == 2:\n",
    "                info_label = parts[0].strip()\n",
    "                info_value = parts[1].strip()\n",
    "                data.append([info_label, \"\", info_value])  # Add with empty 'Output Shape'\n",
    "\n",
    "    # Create and return the DataFrame\n",
    "    return pd.DataFrame(data, columns=col_names)\n",
    "\n",
    "\n",
    "def wandb_log_model_summary_and_architecture(\n",
    "    model, log_summary: bool = True, log_architecture_plot: bool = False\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Logs the model summary and architecture to wandb.\n",
    "\n",
    "    Args:\n",
    "        model: The model to log the summary and architecture for.\n",
    "        log_summary: A boolean indicating whether to log the model summary. Default is True.\n",
    "        log_architecture_plot: A boolean indicating whether to log the model architecture plot. Default is False.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    \"\"\"\n",
    "    if log_summary:\n",
    "        df = model_summary_to_df(model)  # Ensure this function returns a DataFrame\n",
    "        wandb.log({\"Model Summary\": wandb.Table(dataframe=df)})\n",
    "    if log_architecture_plot:\n",
    "        buffer = io.BytesIO()\n",
    "        tf.keras.utils.plot_model(\n",
    "            model,\n",
    "            to_file=buffer,\n",
    "            show_shapes=True,\n",
    "            show_layer_names=True,\n",
    "        )\n",
    "        buffer.seek(0)\n",
    "        wandb.log({\"Model Architecture\": wandb.Image(data_or_path=buffer)})\n",
    "        buffer.close()\n",
    "\n",
    "# start a new run\n",
    "wandb.init(project=\"test\")\n",
    "\n",
    "# Define a complex model (example)\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(64, 64, 3), name='conv2d_1'),\n",
    "    MaxPooling2D(pool_size=(2, 2), name='max_pooling2d_1'),\n",
    "    Conv2D(64, (3, 3), activation='relu', name='conv2d_2'),\n",
    "    MaxPooling2D(pool_size=(2, 2), name='max_pooling2d_2'),\n",
    "    Flatten(name='flatten'),\n",
    "    Dense(128, activation='relu', name='dense_1'),\n",
    "    Dropout(0.5, name='dropout'),\n",
    "    Dense(10, activation='softmax', name='output')  # Assuming 10 classes for classification\n",
    "])\n",
    "\n",
    "# print summary\n",
    "print(model.summary())\n",
    "\n",
    "# Get the model summary DataFrame\n",
    "df = model_summary_to_df(model)\n",
    "\n",
    "# log to wandb\n",
    "# assumes you have already done `wandb.init()`\n",
    "wandb_log_model_summary_and_architecture(model)\n",
    "\n",
    "# Display the DataFrame\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
